{"cells":[{"cell_type":"code","source":"import os, sys\nimport pathlib\nos.getcwd()","metadata":{"tags":[],"cell_id":"424a60d3e0bc40febca342c2ac4c92e1","source_hash":"a82a3ea8","execution_start":1669331350145,"execution_millis":1250,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"'/work'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# # Clone the tensorflow models repository if it doesn't already exist\nif \"models\" in pathlib.Path.cwd().parts:\n  while \"models\" in pathlib.Path.cwd().parts:\n    os.chdir('..')\nelif not pathlib.Path('models').exists():\n  !git clone --depth 1 https://github.com/tensorflow/models","metadata":{"tags":[],"cell_id":"32efdf9cf843486baba1b3fe30e10ba6","source_hash":"4568d9c0","execution_start":1669331350190,"execution_millis":42,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n\nimport os\nimport random\nimport io\nimport imageio\nimport glob\nimport scipy.misc\nimport numpy as np\nfrom six import BytesIO\nfrom PIL import Image, ImageDraw, ImageFont\nfrom IPython.display import display, Javascript\nfrom IPython.display import Image as IPyImage\n\nimport tensorflow as tf\n\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import config_util\nfrom object_detection.utils import visualization_utils as viz_utils\nfrom object_detection.utils import colab_utils\nfrom object_detection.builders import model_builder\n\n%matplotlib inline","metadata":{"tags":[],"cell_id":"fc1d7949801048469657f410efa5aed9","source_hash":"8576f339","execution_start":1669331350233,"execution_millis":4375,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2022-11-24 23:09:10.816964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-24 23:09:10.965903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-11-24 23:09:10.965941: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-11-24 23:09:11.897613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-11-24 23:09:11.897704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-11-24 23:09:11.897714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_util\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualization_utils \u001b[38;5;28;01mas\u001b[39;00m viz_utils\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colab_utils\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mobject_detection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_builder\n\u001b[1;32m     24\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/venv/lib/python3.9/site-packages/object_detection/utils/colab_utils.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m output\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eval_js\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimage_from_numpy\u001b[39m(image):\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"execution_count":3},{"cell_type":"code","source":"#run model builder test\n!python \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\"","metadata":{"tags":[],"cell_id":"18f5a9042c384453a3fc2dc9451acecd","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image_into_numpy_array(path):\n    '''\n    Load an image from file into numpy array\n    Args:\n        path: a file path\n\n    Returns:\n        numpy array\n    '''\n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(BytesIO(img_data))\n    (im_width, im_height) = image.size\n    return np.array(image.getdata()).reshape(\n        (im_height, im_width, 3)).astype(np.uint8)\n\ndef plot_detections(image_np,\n                    boxes,\n                    classes,\n                    scores,\n                    category_index,\n                    figsize=(12, 16),\n                    image_name=None):\n\n    '''\n    Wrapper function to vis detections.\n    '''\n    image_np_with_annotations = image_np.copy()\n    viz_utils.visualize_boxes_and_labels_on_image_array(\n        image_np_with_annotations,\n        boxes,\n        classes,\n        scores,\n        category_index,\n        use_normalized_coordinates=True,\n        min_score_thresh=0.8)\n    if image_name:\n        plt.imsave(image_name, image_np_with_annotations)\n    else:\n        plt.imshow(image_np_with_annotations)","metadata":{"tags":[],"cell_id":"3faa87f5a815490a978779458f5e5aa3","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Downloading data from Roboflow\n%cd \"/content\"\n!curl -L \"https://app.roboflow.com/ds/7TAm80eoDg?key=HrjrgwtTsq\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip","metadata":{"tags":[],"cell_id":"27679ffd182d452598f3a0a01601c46e","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.getcwd()","metadata":{"tags":[],"cell_id":"a7e55c399b324eb6bf47f6d4a698391f","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_record_fname = ''\ntest_record_fname = ''\nlabel_map_pbtxt_fname = ''","metadata":{"tags":[],"cell_id":"81a8988404e44b16b6a73a480bd12c29","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.chdir('/content')","metadata":{"tags":[],"cell_id":"c2425e0dd7184742b6c50fa8d0ba84ca","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.getcwd()","metadata":{"tags":[],"cell_id":"49d6a5516e3648649fd3b591ac8df0e5","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# change chosen model to deploy different models available in the tf2 object detection zoo\nMODELS_CONFIG = {\n    'efficientdet-d0': {\n        'model_name': 'efficientdet_d0_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n        'batch_size': 16\n    },\n    'efficientdet-d1': {\n        'model_name': 'efficientdet_d1_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n        'batch_size': 16\n    },\n    'efficientdet-d2': {\n        'model_name': 'efficientdet_d2_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n        'batch_size': 16\n    },\n        'efficientdet-d3': {\n        'model_name': 'efficientdet_d3_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n        'batch_size': 16\n    }\n}\n\nchosen_model = 'efficientdet-d0'\n\nnum_steps = 25000\nnum_eval_steps = 500\n\nmodel_name = MODELS_CONFIG[chosen_model]['model_name']\npretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\nbase_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\nbatch_size = MODELS_CONFIG[chosen_model]['batch_size']","metadata":{"tags":[],"cell_id":"7c45f609803147a09d1540a4900934d9","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%mkdir \"/content/models/research/deploy/\"\n%cd \"/content/models/research/deploy/\"\nimport tarfile\ndownload_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n\n!wget {download_tar}\ntar = tarfile.open(pretrained_checkpoint)\ntar.extractall()\ntar.close()","metadata":{"tags":[],"cell_id":"3007f0e85e98487dbd51f870135d87b2","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# download base training conf file\n%cd '/content/models/research/deploy'\ndownload_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n!wget {download_config}","metadata":{"tags":[],"cell_id":"e3f6f50ce24b4ee6aa1004c22b78bf8a","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prepare\npipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\nfine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpy-0'\n\ndef get_num_classes(pbtxt_fname):\n    from object_detection.utils import label_map_util\n    label_map = label_map_util.load_labelmap(pbtxt_fname)\n    categories = label_map_util.convert_label_map_to_categories(\n        label_map, max_num_classes=90, use_display_name=True)\n    category_index = label_map_util.create_category_index(categories)\n    return len(category_index.keys())\n\nnum_classes = get_num_classses(label_map_pbtxt_fname)","metadata":{"tags":[],"cell_id":"166d2f86536f4e9ea47f983a23b05aa5","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes","metadata":{"tags":[],"cell_id":"5f930490c32b4429b57688d15ebddc69","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# custom configuration file by splitting dataset, model checkpoint and training parameters into the base pipeline file\n\nimport re\n% cd '/content/models/research/deploy/'\nprint('writing custom conf file')\n\nwith open(pipeline_fname) as f:\n    s = f.read()\nwith open('pipeline_file.config', 'w') as f:\n\n    # fine_tune_checkpoint\n    s = re.sub('fine_tune_checkpoint: \".*?\"',\n               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n\n    # tfrecord files train and test\n    s = re.sub(\n        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n\n    s = re.sub(\n        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n\n    # label_map_path\n    s = re.sub(\n        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n\n    # Set training batch size\n    s = re.sub('batch_size: [0-9]+',\n               'batch_size: {}'.format(batch_size), s)\n\n    # Set training steps, num_steps\n    s = re.sub('num_steps: [0-9]+',\n               'num_steps: {}'.format(num_steps), s)\n    \n    # Set number of classes num_classes\n    s = re.sub('num_classes: [0-9]+',\n               'num_classes: {}'.format(num_classes), s)\n\n    # fine-tune checkpoint type\n    s = re.sub(\n        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n\n    f.write(s)","metadata":{"tags":[],"cell_id":"75a1b8e3e1114e77a9e9ac556317091e","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cat '/content/models/research/deploy/pipeline_file.config'","metadata":{"tags":[],"cell_id":"a7beee919d6d4997982064b4f882c943","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipeline_file = '/content/models/research/deplot/pipeline_file.config'\nmodel_dir = '/content/drive/My Drive/footstat/training/'","metadata":{"tags":[],"cell_id":"cca09f2860624fbd92455dfdef27c1f7","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"4bfadba20e0e4c83a5210bbc1fb87673","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"!python '/content/models/research/object_detection/model_main_tf2.py' \\\n    --pipeline_config_path={pipeline_file} \\\n    --model_dir={model_dir} \\\n    --alsologtostderr \\\n    --num_train_steps={num_steps} \\\n    --sample_l_of_n_eval_examples=1 \\\n    --num_eval_steps={num_eval_steps}","metadata":{"tags":[],"cell_id":"b9e922159569434aa098a919a62d8c1f","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir '/content/drive/My Drive/footstat/training/'","metadata":{"tags":[],"cell_id":"b036e3bf81f143d88958659ee37cc9a9","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls '/content/drive/My Drive/footstat/training/'","metadata":{"tags":[],"cell_id":"94579afec16c4890babb4638f4ae996d","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport numpy as np\n\noutput_directory = '/content/fine_tuned_model'\n\nlast_model_path = '/content/drive/My Drive/footstat/training/'\nprint(last_model_path)\n!python /content/models/research/object_detection/exporter_main_v2.py \\\n    --trained_checkpoint_dir {last_model_path} \\\n    --output_directory {output_directory} \\ \n    --pipeline_config_path {pipeline_file}","metadata":{"tags":[],"cell_id":"00b100e32add49b78c2f2e7e35a714f5","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls '/content/fine_tuned_model/saved_model/'","metadata":{"tags":[],"cell_id":"193976d27cf6455786b81ee2e820ac8e","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# downloading test images from Roboflow\n# export dataset above with format COCO JSON\n# or import your test images via other means\n%mkdir /content/test/\n%cd /content/test/\n# !curl -i \"[LINK HERE]\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip","metadata":{"tags":[],"cell_id":"a7038c5821be414386960b7365b03e0e","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n\nimport io\nimport scipy.misc\nimport numpy as np\nfrom six import BytesIO\nfrom PIL import Image, ImageDraw, ImageFont\n\nimport tensorflow as tf\n\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import config_util\nfrom object_detection,utils import visualization_utils as viz_utils\nfrom object_detection.builders import model_builder\n\n%matplotlib inline","metadata":{"tags":[],"cell_id":"c83ee0d1602c41b2805ca20c5264583d","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image_into_numpy_array(path):\n    '''\n    Load an image from file into a numpy array\n    Puts image into numpy array to ffed into tensorflow graph\n    Note that by conventionn we put it into a numpy array with shape\n    (height, width, channels), where channels=3 for RGB\n\n    Args:\n        path: the file path to the image\n\n    Returns:\n        uint8 numpy array with shape (img_height, img_width, 3)\n    '''\n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(BytesIO(img_data))\n    (im_width, im_height) = image.size\n    return np.array(image.getdata()).reshape(\n        (im_height, im_width, 3)).astype(np.uint8)","metadata":{"tags":[],"cell_id":"6888d4023bfe4cdea670a45465a1956b","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls '/content/drive/My Drive/footstat/training/'","metadata":{"tags":[],"cell_id":"e736d85f1dfb4854b18ae1cb651d1110","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# recover saved model\npipeline_config = pipeline_file\nmodel_dir = '/content/drive/My Drive/footstat/training/ckpt-16'\nconfigs = config_util.get_configs_from_pipeline_file(pipeline_config)\nmodel_config = configs['model']\ndetection_model = model_builder.build(\n    model_config=model_config, is_training=False)\n\nckpt = tf.compat.v2.train.Checkpoint(\n    model=detection_model)\nckpt.restore(os.path.join('/content/drive/My Drive/footstat/training/ckpt-16'))\n\ndef get_model_detection_function(model):\n    '''\n    Get a tf.function for detection\n    '''\n    @tf.function\n    def detect_fn(image):\n        '''\n        Detect objects in image\n        '''\n\n        image, shapes = model.preprocess(image)\n        prediction_dict = model.predict(image, shapes)\n        detections = model.postprocess(prediction_dict, shapes)\n\n        return detections, prediction_dict, tf.reshape(shapes, [-1])\n    \n    return detect_fn\n\ndetect_fn = get_model_detection_function(detection_model)","metadata":{"tags":[],"cell_id":"e60ebf2c92c742e7b715a262f03cccb0","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# map labels for inference decoding\nlabel_map_path = configs['eval_input_config'].label_map_path\nlabel_map = label_map_util.load_labelmap(label_map_path)\ncategories = label_map_util.convert_label_map_to_categories(\n    label_map,\n    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n    use_display_name=True\n)\ncategory_index = label_map_util.create_category_index(categories)\nlabel_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)","metadata":{"tags":[],"cell_id":"a79bdb542bc940ce8e7089647c1e0de5","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\nTEST_IMAGE_PATHS = glob.glob('/content/test/*.jpg')\nimage_path = random.choice(TEST_IMAGE_PATHS)\nimage_np = load_image_into_numpy_array(image_path)\n\n# Things to try:\n# Flip horizontally\n# image_np = np.fliplr(image_np).copy()\n\n# Convert image to grayscale\n# image_np = np.tile(\n#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n\ninput_tensor = tf.convert_to_tensor(\n    np.expand_dims(image_np, 0), dtype=tf.float32)\ndetections, predictions_dict, shapes = detect_fn(input_tensor)\n\nlabel_id_offset = 1\nimage_np_with_detections = image_np.copy()\n\nviz_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_detections,\n      detections['detection_boxes'][0].numpy(),\n      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n      detections['detection_scores'][0].numpy(),\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.5,\n      agnostic_mode=False,\n)\n\nplt.figure(figsize=(12,16))\nplt.imshow(image_np_with_detections)\nplt.show()","metadata":{"tags":[],"cell_id":"a0cc22d4a35e49ae96403c00d84c25f7","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c51dd7fb-2a41-426e-92c7-0ccbf159f7cc' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"fef7159a3c7e4e849451c847bf8cadd7","deepnote_execution_queue":[]}}